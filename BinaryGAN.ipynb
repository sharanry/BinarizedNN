{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 4  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### DATA: Target data and generator input data\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binarize(tensor,quant_mode='det'):\n",
    "    if quant_mode=='det':\n",
    "        return tensor.sign()\n",
    "    else:\n",
    "        return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
    "\n",
    "class BinarizeLinear(nn.Linear):\n",
    "\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        try:\n",
    "            self.exempt = kwargs[\"exempt\"]\n",
    "            del kwargs[\"exempt\"]\n",
    "        except:\n",
    "            self.exempt=False\n",
    "        self.exempt=False\n",
    "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.exempt:\n",
    "#         if input.size(1) != self.excempt:\n",
    "            input.data=Binarize(input.data)\n",
    "        if not hasattr(self.weight,'org'):\n",
    "            self.weight.org=self.weight.data.clone()\n",
    "        self.weight.data=Binarize(self.weight.org)\n",
    "#         print(self.weight.shape)\n",
    "        out = nn.functional.linear(input, self.weight)\n",
    "        if not self.bias is None:\n",
    "            self.bias.org=self.bias.data.clone()\n",
    "            out += self.bias.view(1, -1).expand_as(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = BinarizeLinear(input_size, hidden_size, exempt=True) #1-50\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "#         self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.map2 = BinarizeLinear(hidden_size, hidden_size) #50-50\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "#         self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.map3 = BinarizeLinear(hidden_size, output_size) #50-1\n",
    "#         self.logsoftmax=nn.LogSoftmax()\n",
    "    def forward(self, x):\n",
    "        x = self.htanh1(self.map1(x))\n",
    "        x = self.htanh1(self.map2(x))\n",
    "#         return self.logsoftmax(self.map3(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = BinarizeLinear(input_size*2, hidden_size, exempt=True) #100-50\n",
    "        print((input_size, hidden_size), self.map1.weight.shape)\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "#         self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.map2 = BinarizeLinear(hidden_size, hidden_size) #50-50\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "#         self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.map3 = BinarizeLinear(hidden_size, output_size) #50-1\n",
    "#         self.logsoftmax=nn.LogSoftmax()\n",
    "        self.htanh3 = nn.Hardtanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.htanh1(self.map1(x))\n",
    "        x = self.htanh1(self.map2(x))\n",
    "        return self.htanh3(self.map3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50) torch.Size([50, 200])\n"
     ]
    }
   ],
   "source": [
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "# D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharan/anaconda3/envs/GPUReady/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.0/0.7810595631599426 G: 0.0 (Real: [4.033352342844009, 1.0754584511117078], Fake: [4.685608332157135, 2.4548669928369327]) \n",
      "200: D: 0.0/27.63102149963379 G: 27.63102149963379 (Real: [4.17116320848465, 1.3007859089802456], Fake: [4.7590951704606415, 2.7135804101719927]) \n",
      "400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.053149722963571, 1.2402774566304324], Fake: [3.41772410299629, 3.0358430610362093]) \n",
      "600: D: 0.0/27.63102149963379 G: 27.63102149963379 (Real: [3.815350051522255, 1.2130965964084066], Fake: [4.004249610081315, 3.023410910800886]) \n",
      "800: D: 0.0/27.63102149963379 G: 0.0 (Real: [4.139606406390667, 1.3132308233927945], Fake: [8.70237875878811, 3.16160790726547]) \n",
      "1000: D: 27.63102149963379/27.63102149963379 G: 0.0 (Real: [3.9563324177265167, 1.3848358407513288], Fake: [7.8920968319475655, 3.362056514264185]) \n",
      "1200: D: 0.0/0.0 G: 27.63102149963379 (Real: [4.027162272334099, 1.301330310122871], Fake: [7.692215462699533, 3.543574247039918]) \n",
      "1400: D: 0.0/0.0 G: 27.63102149963379 (Real: [3.986919569969177, 1.1384231083271328], Fake: [7.964254440963268, 3.075548746024447]) \n",
      "1600: D: 0.0/0.0 G: 0.0 (Real: [3.987625568509102, 1.4188953823598787], Fake: [7.915860926061868, 3.0642409735584777]) \n",
      "1800: D: 0.0/0.0 G: 27.63102149963379 (Real: [3.994891184568405, 1.2842608441308208], Fake: [8.099526886940003, 2.601287990920583]) \n",
      "2000: D: 0.6342253684997559/0.0 G: 27.63102149963379 (Real: [4.036413484811783, 1.1356324562676259], Fake: [8.601206870079041, 2.156045638345469]) \n",
      "2200: D: 0.0/27.63102149963379 G: 27.63102149963379 (Real: [4.119657142162323, 0.9983541034367224], Fake: [7.699364404678345, 2.379510477612416]) \n",
      "2400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.1215647292137145, 1.2043278428739617], Fake: [8.226145491600036, 2.3873660356190407]) \n",
      "2600: D: 0.0/0.0 G: 27.63102149963379 (Real: [3.8516451644897463, 1.2375182751995986], Fake: [8.281201224327088, 2.5461528195707546]) \n",
      "2800: D: 0.0/27.63102149963379 G: 27.63102149963379 (Real: [4.0124962246418, 1.3071292994469754], Fake: [7.7474874961376194, 2.3890059925630345]) \n",
      "3000: D: 0.769622802734375/0.0 G: 27.63102149963379 (Real: [4.216540084481239, 1.1656975908167768], Fake: [7.963083567619324, 2.364796977222594]) \n",
      "3200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.187848392724991, 1.0934851246782602], Fake: [8.468329591751099, 2.3070996584329952]) \n",
      "3400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.118106744289398, 1.1430017176048914], Fake: [8.400348521471024, 2.221486089649979]) \n",
      "3600: D: 0.0/0.0 G: 27.63102149963379 (Real: [4.286604709625244, 1.1603267493678442], Fake: [7.3330551886558535, 2.752978152222585]) \n",
      "3800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.023743561506271, 1.1542826320433632], Fake: [7.561752127408981, 3.0104173504859095]) \n",
      "4000: D: 27.63102149963379/27.63102149963379 G: 27.63102149963379 (Real: [3.8133023762702942, 1.2568131073574393], Fake: [7.105310174226761, 2.6823654287729184]) \n",
      "4200: D: 2.0979084968566895/0.0 G: 27.63102149963379 (Real: [3.73362131357193, 1.1442827629314927], Fake: [7.607300257086754, 2.8108316669120765]) \n",
      "4400: D: 0.03755846619606018/0.0 G: 27.63102149963379 (Real: [3.917157388925552, 1.3493068255856198], Fake: [7.7103389036655425, 2.8898511427340092]) \n",
      "4600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.9359478056430817, 1.3010203215874208], Fake: [7.885615308284759, 2.3245400841635444]) \n",
      "4800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.114948347806931, 1.2288594624380924], Fake: [7.521848222017288, 3.034144986467978]) \n",
      "5000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.122101511955261, 1.2165583668968813], Fake: [7.646901782751083, 2.5783715944996906]) \n",
      "5200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.114528192281723, 1.3789066344365788], Fake: [8.15068397641182, 2.4026049913191607]) \n",
      "5400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.9477697879076006, 1.3643745297124732], Fake: [7.7046828985214235, 2.8370094299390356]) \n",
      "5600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.8859680032730104, 1.1122649919542396], Fake: [7.828529717922211, 2.3703037488352723]) \n",
      "5800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.0436783850193025, 1.2179055923661204], Fake: [7.971218515634536, 2.702004509021908]) \n",
      "6000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.8751816642284393, 1.2205064840394737], Fake: [7.571796371936798, 2.8188760678231515]) \n",
      "6200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.039295201003552, 1.3283195163836548], Fake: [7.940713677406311, 2.7432489202494925]) \n",
      "6400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.01337154507637, 1.3857683411784372], Fake: [7.793854541778565, 2.654461243050119]) \n",
      "6600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.916455569267273, 1.1893888602643308], Fake: [7.757918719053269, 2.812856555566464]) \n",
      "6800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.059304192066192, 1.2246045209775487], Fake: [7.520706157684327, 2.496872514026845]) \n",
      "7000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.726089919805527, 1.2391121419154252], Fake: [8.172200289964676, 2.5259771002210183]) \n",
      "7200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.088781492710114, 1.2619004156643543], Fake: [8.05678657412529, 2.740626128033358]) \n",
      "7400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.947468169927597, 1.2206244629268783], Fake: [7.681784590482712, 2.417828289894206]) \n",
      "7600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.038188928365708, 1.2881208277873093], Fake: [8.142384361028672, 2.624770762305497]) \n",
      "7800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.117545316368341, 1.292758574294552], Fake: [8.027189301252365, 2.8236213774820103]) \n",
      "8000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.947562318444252, 1.1925485711571397], Fake: [7.4480606150627136, 2.8698040783556973]) \n",
      "8200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.939710383415222, 1.294159160739724], Fake: [7.402173843383789, 2.595801493081705]) \n",
      "8400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.95289977312088, 1.2175764617573734], Fake: [7.36641604423523, 2.8486876102137737]) \n",
      "8600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.0067695462703705, 1.301686230901354], Fake: [7.255195863246918, 2.767851760212915]) \n",
      "8800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.08565562158823, 1.3752973197037202], Fake: [7.24965077996254, 2.901253603113439]) \n",
      "9000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.9365161752700804, 1.1962634080803216], Fake: [7.673351926803589, 2.6673840230356807]) \n",
      "9200: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.027051757574082, 1.3903489892214538], Fake: [7.5080534672737125, 2.9656993180563265]) \n",
      "9400: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.0874176180362705, 1.251388701262337], Fake: [7.175212968587875, 2.9397648461037615]) \n",
      "9600: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [3.974897485971451, 1.2509294494810281], Fake: [7.8757975077629085, 2.9352939343589495]) \n",
      "9800: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.147972785234451, 1.313415012688921], Fake: [7.8141981112957, 2.92367708752825]) \n",
      "10000: D: 27.63102149963379/0.0 G: 27.63102149963379 (Real: [4.182408681511879, 1.3841747855462754], Fake: [7.844528453350067, 2.6281811467334437]) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-f71b16a42e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Only optimizes G's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#         print(\"################\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'org'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPUReady/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \"\"\"\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPUReady/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GPUReady/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = (D(preprocess(d_real_data)) + 1)/2\n",
    "#         d_real_decision = D(d_real_data)\n",
    "#         print(d_real_decision)\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = (D(preprocess(d_fake_data.t())) + 1)/2\n",
    "#         d_fake_decision = D(d_fake_data.t())\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        \n",
    "        d_fake_error.backward()\n",
    "        for p in list(D.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "#         print(1)\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "        for p in list(D.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = (D(preprocess(g_fake_data.t())) + 1)/2\n",
    "#         print(preprocess(g_fake_data.t()).shape, dg_fake_decision)\n",
    "        #         dg_fake_decision = D(g_fake_data.t())\n",
    "#         print(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        for p in list(G.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "#         for i.grad in G.parameters():\n",
    "#             print(i)\n",
    "#         print(g_fake_data.grad)\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "#         print(\"################\")\n",
    "        for p in list(G.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "        \n",
    "#         for i in G.parameters():\n",
    "#             print(i)\n",
    "            \n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPUReady)",
   "language": "python",
   "name": "gpuready"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
